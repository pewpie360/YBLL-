{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3263466f",
   "metadata": {},
   "source": [
    "# Advance GenAI Workshop\n",
    "author: King Matthew Ochoa\n",
    "\n",
    "---\n",
    "## Setup Preparation\n",
    "\n",
    "Before we can do anything, we should have the necessary python libraries. The cell below installs them using pip package manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03cd024a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T07:08:04.165628Z",
     "iopub.status.busy": "2025-04-12T07:08:04.164120Z",
     "iopub.status.idle": "2025-04-12T07:08:08.319474Z",
     "shell.execute_reply": "2025-04-12T07:08:08.318969Z",
     "shell.execute_reply.started": "2025-04-12T07:08:04.165628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from tiktoken) (2024.7.24)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
      "Downloading tiktoken-0.9.0-cp311-cp311-win_amd64.whl (893 kB)\n",
      "   ---------------------------------------- 0.0/893.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 893.9/893.9 kB 10.0 MB/s eta 0:00:00\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cfde06f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T07:08:12.014551Z",
     "iopub.status.busy": "2025-04-12T07:08:12.013454Z",
     "iopub.status.idle": "2025-04-12T07:08:21.513678Z",
     "shell.execute_reply": "2025-04-12T07:08:21.513678Z",
     "shell.execute_reply.started": "2025-04-12T07:08:12.014551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[791, 6348, 8319, 481, 93484, 706, 1027, 11102, 323, 1457, 25912, 716, 481, 13]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "def get_tokens(txt, model):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    tokens = encoding.encode(txt)\n",
    "    return tokens\n",
    "\n",
    "tokens = get_tokens(\"The irreplaceable vase has been broken and now irreperable.\", \"gpt-4\")\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005c61b8",
   "metadata": {},
   "source": [
    "# Labwork\n",
    "### We will need to install a certain version of langchain, langchain-groq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5312ceb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T07:08:37.293728Z",
     "iopub.status.busy": "2025-04-12T07:08:37.293728Z",
     "iopub.status.idle": "2025-04-12T07:08:40.406673Z",
     "shell.execute_reply": "2025-04-12T07:08:40.405669Z",
     "shell.execute_reply.started": "2025-04-12T07:08:37.293728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-groq in c:\\users\\atara\\anaconda3\\lib\\site-packages (0.3.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from langchain-groq) (0.3.51)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from langchain-groq) (0.22.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (2.5.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\atara\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (4.11.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (0.3.30)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (6.0.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (24.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\atara\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\atara\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain-groq) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (3.10.16)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.14.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\atara\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (1.26.20)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-groq\n",
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2e63a1",
   "metadata": {},
   "source": [
    "### Saving the groq key created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7523c999",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T07:08:55.996662Z",
     "iopub.status.busy": "2025-04-12T07:08:55.996662Z",
     "iopub.status.idle": "2025-04-12T07:08:56.001029Z",
     "shell.execute_reply": "2025-04-12T07:08:55.999961Z",
     "shell.execute_reply.started": "2025-04-12T07:08:55.996662Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "your_api_key = \"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\"\n",
    "os.environ['GROQ_API_KEY'] = your_api_key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a55d8a2",
   "metadata": {},
   "source": [
    "### Importing the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "904b70cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T07:08:59.690357Z",
     "iopub.status.busy": "2025-04-12T07:08:59.690357Z",
     "iopub.status.idle": "2025-04-12T07:09:00.927215Z",
     "shell.execute_reply": "2025-04-12T07:09:00.927215Z",
     "shell.execute_reply.started": "2025-04-12T07:08:59.690357Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a30aaa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T07:12:10.667599Z",
     "iopub.status.busy": "2025-04-12T07:12:10.667599Z",
     "iopub.status.idle": "2025-04-12T07:12:12.033993Z",
     "shell.execute_reply": "2025-04-12T07:12:12.032987Z",
     "shell.execute_reply.started": "2025-04-12T07:12:10.667599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hallo, willkommen im YBLL-Workshop!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Groq LLM\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "#setup the prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a translator from english to german. :D\"\"\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "prompt_num2 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a translator from english to tagalog. :D\"\"\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "#define the chain\n",
    "chain = prompt | llm \n",
    "chain2 = prompt_num2 | llm\n",
    "\n",
    "#call the LLM\n",
    "sentence = \"Hello welcome to YBLL Workshop!\"\n",
    "result = chain.invoke({\"input\": sentence})\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "137b5674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hallo, ich hei√üe Christian Jay Baguio.\\n\\n(I translated \"Hello, My Name is\" to \"Hallo, ich hei√üe\" which is a more common way to introduce oneself in German. \"Ich hei√üe\" means \"My name is\".)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_num2 = 'Hello, My Name is Christian Jay Baguio'\n",
    "result_num2 = chain.invoke({\"input\": sentence_num2})\n",
    "result_num2.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25638f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kumusta, Ang pangalan ko ay Christian Jay Baguio. \\n\\n(Hello, My Name is Christian Jay Baguio - translated to Tagalog)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_num3 = 'Hello, My Name is Christian Jay Baguio'\n",
    "result_num2 = chain2.invoke({\"input\": sentence_num3})\n",
    "result_num2.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1d10128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Kees Van Der Westen Speedster\",\n",
      "  \"price\": 14499,\n",
      "  \"features\": [\n",
      "    \"Dual boilers for brewing and steaming\",\n",
      "    \"PID temperature control\",\n",
      "    \"Pre-infusion system\",\n",
      "    \"Customizable aesthetics\",\n",
      "    \"Exceptional thermal stability\",\n",
      "    \"Intuitive operation via a lever system\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Initialize Groq LLM\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Define the expected JSON structure\n",
    "parser = JsonOutputParser(pydantic_object={\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"name\": {\"type\": \"string\"},\n",
    "        \"price\": {\"type\": \"number\"},\n",
    "        \"features\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\"type\": \"string\"}\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "# Create a simple prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Extract product details into JSON with this structure:\n",
    "        {{\n",
    "            \"name\": \"product name here\",\n",
    "            \"price\": number_here_without_currency_symbol,\n",
    "            \"features\": [\"feature1\", \"feature2\", \"feature3\"]\n",
    "        }}\"\"\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Create the chain that guarantees JSON output\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "def parse_product(description: str) -> dict:\n",
    "    result = chain.invoke({\"input\": description})\n",
    "    print(json.dumps(result, indent=2))\n",
    "\n",
    "        \n",
    "# Example usage\n",
    "description = \"\"\"The Kees Van Der Westen Speedster is a high-end, single-group espresso machine known for its precision, performance, \n",
    "and industrial design. Handcrafted in the Netherlands, it features dual boilers for brewing and steaming, PID temperature control for \n",
    "consistency, and a unique pre-infusion system to enhance flavor extraction. Designed for enthusiasts and professionals, it offers \n",
    "customizable aesthetics, exceptional thermal stability, and intuitive operation via a lever system. The pricing is approximatelyt $14,499 \n",
    "depending on the retailer and customization options.\"\"\"\n",
    "\n",
    "parse_product(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a08a38",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801502ee",
   "metadata": {},
   "source": [
    "## It's your turn! \n",
    "# Activity 1\n",
    "üß†  Prompt Engineering Exercise: Sentiment Analyzer\n",
    "### üì¶ Scenario \n",
    "#### Given the dataframe below, add the column value for the sentiment of the expression.\n",
    "\n",
    "### üéØ Objective  \n",
    "#### Craft a high-quality prompt that fills out the empty `sentiment` column of the pandas dataframe.\n",
    "\n",
    "*hint: create a function and loop over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10706c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expression</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is amazing!</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can't stop smiling!</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm so thrilled!</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I feel really down.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is tough for me.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I'm just not myself today.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>It's just another day.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm okay.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>It is what it is.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This is frustrating!</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I'm really upset about this.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I can't believe this happened!</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Couldn't be happier today!</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>This just feels right.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I love this!</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I'm heartbroken.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Everything feels heavy.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wish things were different.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Just going through the motions.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I'm feeling indifferent.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What did I do to deserve this?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>I'm at my wit's end!</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Overjoyed with this news!</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>I'm on cloud nine!</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Feeling blessed and grateful.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Life's full of ups and downs.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Trying to stay positive.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Everything's a bit overwhelming.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>I'm content with where I am.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Finally, some peace and quiet.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>That was the last straw!</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>They always let me down.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          expression sentiment\n",
       "0                   This is amazing!          \n",
       "1              I can't stop smiling!          \n",
       "2                   I'm so thrilled!          \n",
       "3                I feel really down.          \n",
       "4              This is tough for me.          \n",
       "5         I'm just not myself today.          \n",
       "6             It's just another day.          \n",
       "7                          I'm okay.          \n",
       "8                  It is what it is.          \n",
       "9               This is frustrating!          \n",
       "10      I'm really upset about this.          \n",
       "11    I can't believe this happened!          \n",
       "12        Couldn't be happier today!          \n",
       "13            This just feels right.          \n",
       "14                      I love this!          \n",
       "15                  I'm heartbroken.          \n",
       "16           Everything feels heavy.          \n",
       "17       Wish things were different.          \n",
       "18   Just going through the motions.          \n",
       "19          I'm feeling indifferent.          \n",
       "20    What did I do to deserve this?          \n",
       "21              I'm at my wit's end!          \n",
       "22         Overjoyed with this news!          \n",
       "23                I'm on cloud nine!          \n",
       "24     Feeling blessed and grateful.          \n",
       "25     Life's full of ups and downs.          \n",
       "26          Trying to stay positive.          \n",
       "27  Everything's a bit overwhelming.          \n",
       "28      I'm content with where I am.          \n",
       "29    Finally, some peace and quiet.          \n",
       "30          That was the last straw!          \n",
       "31          They always let me down.          "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sentiment_df = pd.DataFrame([\n",
    "    \"This is amazing!\",\n",
    "    \"I can't stop smiling!\",\n",
    "    \"I'm so thrilled!\",\n",
    "    \"I feel really down.\",\n",
    "    \"This is tough for me.\",\n",
    "    \"I'm just not myself today.\",\n",
    "    \"It's just another day.\",\n",
    "    \"I'm okay.\",\n",
    "    \"It is what it is.\",\n",
    "    \"This is frustrating!\",\n",
    "    \"I'm really upset about this.\",\n",
    "    \"I can't believe this happened!\",\n",
    "    \"Couldn't be happier today!\",\n",
    "    \"This just feels right.\",\n",
    "    \"I love this!\",\n",
    "    \"I'm heartbroken.\",\n",
    "    \"Everything feels heavy.\",\n",
    "    \"Wish things were different.\",\n",
    "    \"Just going through the motions.\",\n",
    "    \"I'm feeling indifferent.\",\n",
    "    \"What did I do to deserve this?\",\n",
    "    \"I'm at my wit's end!\",\n",
    "    \"Overjoyed with this news!\",\n",
    "    \"I'm on cloud nine!\",\n",
    "    \"Feeling blessed and grateful.\",\n",
    "    \"Life's full of ups and downs.\",\n",
    "    \"Trying to stay positive.\",\n",
    "    \"Everything's a bit overwhelming.\",\n",
    "    \"I'm content with where I am.\",\n",
    "    \"Finally, some peace and quiet.\",\n",
    "    \"That was the last straw!\",\n",
    "    \"They always let me down.\"\n",
    "], columns= ['expression'])\n",
    "sentiment_df['sentiment'] = ''\n",
    "\n",
    "sentiment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1a0959",
   "metadata": {},
   "source": [
    "# Activity 2\n",
    "üß†  Prompt Engineering Exercise: Structured Insight Extraction\n",
    "### üì¶ Scenario \n",
    "#### A teacher gives a riddle to her class:\n",
    "\n",
    "‚ÄúIf you take the number of letters in the English word for the smallest prime number, multiply that by the position of that prime in the list of primes, and then subtract the number of letters in the word for the next prime, what do you get?‚Äù\n",
    "\n",
    "What is the final result?\n",
    "\n",
    "### üéØ Objective  \n",
    "#### Utilize CoT prompting technique to solve the riddle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce85e77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello. It's nice to be here at the YBLL Workshop. What's the focus of this workshop, and how can I assist or participate?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 47, 'total_tokens': 79, 'completion_time': 0.130159755, 'prompt_time': 0.003094667, 'queue_time': 0.24896656700000003, 'total_time': 0.133254422}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9a8b91ba77', 'finish_reason': 'stop', 'logprobs': None}, id='run-dce49814-1225-4eed-8039-6ceb1afbe7af-0', usage_metadata={'input_tokens': 47, 'output_tokens': 32, 'total_tokens': 79})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Groq LLM\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "#setup the prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "                System prompt here.\n",
    "                \"\"\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "#define the chain\n",
    "chain = prompt | llm \n",
    "\n",
    "#call the LLM\n",
    "user_prompt = \"Hello welcome to YBLL Workshop!\"\n",
    "result = chain.invoke({\"input\": user_prompt})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e697f2",
   "metadata": {},
   "source": [
    "# Activity 3: \n",
    "üß† Prompt Engineering Exercise: Structured Insight Extraction\n",
    "\n",
    "\n",
    "üì¶ Scenario\n",
    "You are given a small dataset of customer feedback in free-form text. Your task is to design a prompt that turns these messy text entries into structured information suitable for a spreadsheet or database.\n",
    "\n",
    "üéØ Objective\n",
    "Craft a high-quality prompt that extracts structured insights from unstructured text data, focusing on clarity, structure, and consistency of output.\n",
    "\n",
    "Design a single prompt that takes the above list and returns a structured table with the following columns:\n",
    "\n",
    "| Feedback | Sentiment | Issues Mentioned | Actionable Suggestion |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbeeda4",
   "metadata": {},
   "source": [
    "1. \"Shipping was delayed but the product quality was excellent.\"\n",
    "2. \"The support team was unhelpful and I never got a response to my email.\"\n",
    "3. \"Loved the fast delivery. Great material. Will definitely buy again!\"\n",
    "4. \"Not happy with the purchase. Item didn‚Äôt match the photo.\"\n",
    "5. \"Amazing experience! Great fit, quick delivery, and friendly customer service.\"\n",
    "6. \"The shirt fabric feels cheap. It shrank after one wash.\"\n",
    "7. \"Packaging was impressive. Arrived a day early!\"\n",
    "8. \"Customer service ignored my refund request for a week.\"\n",
    "9. \"Website was confusing. Took me a while to find the size guide.\"\n",
    "10. \"Very satisfied. My third order and still great quality.\"\n",
    "11. \"The pants were too tight even though I followed the sizing chart.\"\n",
    "12. \"Got the wrong color. Asked for black, received navy blue.\"\n",
    "13. \"Product is good, but I wish the price was more affordable.\"\n",
    "14. \"Quick checkout and smooth delivery. Thanks!\"\n",
    "15. \"Item had a weird smell out of the box. Needed to wash it first.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4e9c146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello. It's nice to be here at the YBLL Workshop. I'm excited to learn and participate. What's the focus of the workshop, and what can I expect to learn or accomplish today?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 47, 'total_tokens': 90, 'completion_time': 0.156363636, 'prompt_time': 0.00267654, 'queue_time': 0.24169566, 'total_time': 0.159040176}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3f3b593e33', 'finish_reason': 'stop', 'logprobs': None}, id='run-7d062ba4-7da4-4633-8178-2ec266c7402a-0', usage_metadata={'input_tokens': 47, 'output_tokens': 43, 'total_tokens': 90})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Groq LLM\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "#setup the prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "                System prompt here.\n",
    "                \"\"\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "#define the chain\n",
    "chain = prompt | llm \n",
    "\n",
    "#call the LLM\n",
    "user_prompt = \"Hello welcome to YBLL Workshop!\"\n",
    "result = chain.invoke({\"input\": user_prompt})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39d8874",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
